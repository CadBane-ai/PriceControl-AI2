# Story 2.3: Create Backend AI Chat Stream

## Status
Ready for Review

## Story
As a developer, I want to create a backend API route that streams data from the Cerebras LLM service via OpenRouter, so that the frontend can receive and display the LLM's response.

## Context
This story builds the server endpoint that accepts a chat transcript, calls the LLM, and streams tokens back to the client. It connects the Story 2.2 frontend logic to a real endpoint using the Vercel AI SDK, replacing local-only state updates. Model selection (Story 2.4) will consume the optional `mode` and `model` fields passed through this route.

## Acceptance Criteria
1. An API route exists at `apps/web/app/api/ai/route.ts` (exposed as `/api/ai`) using the Next.js App Router.
2. The route accepts a JSON payload containing the chat `messages` array plus optional `conversationId`, `mode`, and explicit `model` overrides.
3. Requests require an authenticated NextAuth session; unauthenticated calls return `401 Unauthorized`.
4. When `OPENROUTER_API_KEY` is present, the route connects to OpenRouter (Cerebras provider) and streams tokens back to the client; otherwise a deterministic mock streaming response is returned for local development.
5. Streaming responses integrate with the Story 2.2 chat UI using Vercel’s `useChat` hook so the frontend renders incremental tokens.

## Tasks / Subtasks
- [x] Environment & Documentation
  - [x] Add `.env.example` entries for `OPENROUTER_API_KEY` (and optional `OPENROUTER_API_URL` if needed) and document setup in `apps/web/README.md`.
- [x] Implement `/api/ai`
  - [x] Create `apps/web/app/api/ai/route.ts` with request validation (Zod) covering `messages`, `conversationId`, `mode`, and `model`.
  - [x] Enforce NextAuth session checks; return 401 when absent.
  - [x] When OpenRouter credentials are present, call the Cerebras model via Vercel AI SDK and stream responses; otherwise emit a mock stream with diagnostics logged.
  - [x] Forward `mode` and `model` values to the provider request for future stories.
- [x] Frontend Wiring
  - [x] Update `apps/web/app/(protected)/dashboard/page.tsx` to call `/api/ai` through `useChat`, ensuring streaming tokens render in the thread.
  - [x] Preserve existing loading UX and ensure errors display without regressing Story 2.2 behaviors.
- [x] Testing
  - [x] API tests cover authentication gating, OpenRouter call path (mocked), mock fallback, and payload validation failures.
  - [x] Frontend tests ensure submitting a prompt hits `/api/ai`, streams assistant text, and forwards `mode`/`model` when provided.

## Dev Notes
- Pathing: Next.js App Router file `apps/web/app/api/ai/route.ts`.
- Authentication: Use `getServerSession(authOptions)`; return 401 when missing.
- OpenRouter Integration: Use Vercel AI SDK helpers (`OpenAIStream`, `StreamingTextResponse`) configured with `OPENROUTER_API_KEY` and the Cerebras model group. Include `mode` and `model` in the payload so Story 2.4 can switch models.
- Mock Mode: When env variables are absent, return a deterministic stream (e.g., canned tokens) to keep local development unblocked.
- Persistence: Do not persist messages yet; conversation storage remains future scope.
- Error Handling: Surface provider errors with 5xx responses and include safe diagnostics for logs only.

## Scrum Master Notes
- Keep Story 2.4 (model selection) separate; ensure `mode`/`model` are simply forwarded when provided.
- Do not introduce message persistence; focus on streaming response plumbing.
- Coordinate with Story 2.7 to avoid breaking conversation sidebar UX.

## Testing
- Manual
  - Login, navigate to `/dashboard`, send a prompt; verify tokens stream from `/api/ai` when `OPENROUTER_API_KEY` is configured.
  - Remove or unset `OPENROUTER_API_KEY`; verify mock streaming fallback works.
  - Attempt to call `/api/ai` unauthenticated; expect 401.
- Automated
  - API tests mock OpenRouter to confirm streaming and mock fallback behaviors.
  - Frontend test ensures `useChat` submits to `/api/ai`, forwards `mode`/`model`, and renders streamed output.

## QA Results

### Review Date: 2025-09-18
### Reviewed By: Quinn (Test Architect)

### NFR Assessment
- **Security: CONCERNS**. Need to ensure robust protection of `OPENROUTER_API_KEY` and implement rate limiting/abuse prevention on the `/api/ai` endpoint.
- **Performance: CONCERNS**. Define performance targets for streaming responses. Consider strategies for optimizing data transfer and handling potential LLM service latencies.
- **Reliability: CONCERNS**. Implement comprehensive error handling for external LLM service failures, including retry mechanisms, circuit breakers, and clear error messages to the client.
- **Maintainability: PASS**.

### Requirements Traceability
- All Acceptance Criteria are covered by implemented tasks and tests.

### Risk Assessment
- **Critical Risks:** SEC-001 (Unauthenticated access to the AI endpoint) - Addressed by AC3 and corresponding implementation/tests.
- **High Risks:** SEC-002 (API key leakage) - Mitigated by using environment variables, but still a concern if not properly managed in deployment.
- **Medium Risks:** TECH-002 (OpenRouter API errors), TECH-001 (Incorrect streaming implementation) - Addressed by implementation and testing.
- **Low Risks:** OPS-001 (Missing env variables) - Addressed by mock fallback.

### Compliance Check
- Coding Standards: ✓
- Project Structure: ✓
- Testing Strategy: ✓
- All ACs Met: ✓

### Recommended Status
✓ Ready for Done

### Review Date: 2025-09-19
### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment
- Regression in the OpenRouter path: the handler no longer constrains execution to the Cerebras provider or records usage limits, and it skips forwarding the `mode` flag altogether (`apps/web/app/api/ai/route.ts:27-41`). This violates the architecture guidance and removes guardrails that existed in the prior revision.
- Request validation was loosened to `z.any()` per message (`apps/web/lib/validators.ts:30-34`), which permits malformed payloads and weakens input hardening.

### Requirements Traceability
- **AC1 (POST route exists)** – covered by `registers POST handler` in `apps/web/__tests__/api-ai-route.test.ts:92`.
- **AC2 (payload validation)** – `should return 400 if request body is invalid` in `apps/web/__tests__/api-ai-route.test.ts:107`.
- **AC3 (auth gating)** – `should return 401 if user is not authenticated` in `apps/web/__tests__/api-ai-route.test.ts:96`.
- **AC4 (streaming + mode/model forwarding)** – streaming path tests exist, but `mode` is never forwarded and provider constraints were removed, so this AC remains unmet (`apps/web/app/api/ai/route.ts:27-41`).
- **AC5 (frontend wiring)** – `Dashboard useChat integration` suite verifies hook configuration and streaming UI behaviour (`apps/web/__tests__/chat-usechat-integration.test.tsx:99-141`).

### Test Coverage Review
- `pnpm --filter @pricecontrol/web test` (Vitest) – PASS with expected environment warnings.
- Coverage gaps: no automated check asserts that `mode` or provider restrictions reach OpenRouter, nor that usage limits still apply.

### NFR Assessment
- **Security:** FAIL – removal of rate limiting/usage tracking and provider pinning exposes the endpoint to abuse and uncapped spend (`apps/web/app/api/ai/route.ts:29-42`). Input schema now accepts arbitrary message objects (`apps/web/lib/validators.ts:30-34`).
- **Performance:** CONCERNS – the new OpenRouter call lacks timeout/error handling, so slow upstream responses will now bubble up as unhandled errors.
- **Reliability:** FAIL – upstream failures will throw uncaught exceptions, returning generic 500s without the prior graceful fallback logic.
- **Maintainability:** CONCERNS – defensive utilities (`resolveModelForMode`, `buildCompletionsUrl`) were dropped, making future stories harder to extend.

### Risks & Issues
- High: AC4 broken because `mode` is ignored and provider guardrails were removed (`apps/web/app/api/ai/route.ts:35-38`).
- High: Usage throttling and spend protection logic eliminated, re-opening prior SEC/OPS risks (`apps/web/app/api/ai/route.ts:29-42`).
- Medium: Schema allows arbitrary message structures, increasing risk of runtime failures downstream (`apps/web/lib/validators.ts:30-34`).

### Recommendations
- Restore the usage tracking, rate limiting, and provider restriction logic from the previous implementation and add regression tests to lock them in.
- Forward `mode` alongside `model` in the OpenRouter payload and assert this behaviour in tests.
- Tighten request validation to the documented message shape and add error handling around the OpenRouter call so failures surface as structured responses.

### Test Evidence
- Vitest suite execution: `pnpm --filter @pricecontrol/web test`.

### Gate Recommendation
- Gate Decision: **FAIL** – AC4 is unmet and critical security/reliability regressions were introduced. Restore safeguards before promotion.

### Review Date: 2025-09-19
### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment
- Guardrails reinstated: usage tracking, Cerebras-only provider enforcement, and structured error handling are back in place (`apps/web/app/api/ai/route.ts:26-117`).
- Input validation now enforces structured chat messages and enumerated modes (`apps/web/lib/validators.ts:30-40`).
- Integration tests cover mode forwarding, provider restrictions, and usage limits (`apps/web/__tests__/api-ai-route.test.ts:96-189`), eliminating the previous regression risk.

### Requirements Traceability
- **AC1** – `/api/ai` POST handler verified by `registers POST handler` (`apps/web/__tests__/api-ai-route.test.ts:86`).
- **AC2** – Invalid payload returns `400` (`apps/web/__tests__/api-ai-route.test.ts:102`).
- **AC3** – Auth gating enforced (`apps/web/__tests__/api-ai-route.test.ts:92`).
- **AC4** – OpenRouter path now forwards `mode`/`model`, enforces Cerebras provider, and provides mock fallback with guardrails (`apps/web/app/api/ai/route.ts:45-117`) and associated tests (`apps/web/__tests__/api-ai-route.test.ts:132-168`).
- **AC5** – Frontend integration confirmed via `Dashboard useChat integration` (`apps/web/__tests__/chat-usechat-integration.test.tsx:98-151`).

### Test Coverage Review
- `pnpm --filter @pricecontrol/web test` (Vitest) – PASS (expected warnings for absent env secrets remain).
- New unit tests assert usage-limiting, provider enforcement, and mock fallback behaviour.

### NFR Assessment
- **Security:** PASS – Usage throttling restored and provider restricted to Cerebras; request schema hardened.
- **Performance:** PASS – Stream pipeline mirrors prior baseline; fallback path keeps local development responsive.
- **Reliability:** PASS – Provider failures now return structured 502 responses and mock fallback remains available.
- **Maintainability:** PASS – Helpers (`resolveModelForMode`, `buildCompletionsUrl`) reinstated, keeping responsibilities well encapsulated.

### Risks & Issues
- None blocking. Monitor upstream latency; consider future circuit-breaker once production traffic is known.

### Recommendations
- Optional future: add telemetry around 502 responses to observe upstream reliability trends.

### Test Evidence
- Vitest run: `pnpm --filter @pricecontrol/web test`.

### Gate Recommendation
- Gate Decision: **PASS** – All acceptance criteria satisfied and prior NFR concerns resolved.

## PO Validation

PO Review Date: 2025-09-17
Decision: PASS with follow-ups

Validation Summary
- Alignment to PRD 2.3 confirmed (docs/prd/7-epic-2-core-llm-interaction-governance.md#story-23-create-backend-ai-chat-stream) including optional `mode`/`model` fields and OpenRouter streaming fallback.
- Architecture compatibility verified with docs/architecture/6-components.md#llm-gateway-service and docs/architecture/8-core-workflows.md#ai-chat-query-with-tool-use.
- Follow-ups: ensure `.env.example` references `OPENROUTER_API_KEY` (not legacy Cerebras key) and API spec path is synced (`/api/ai`).

## PO Checklist Results
- Mode: YOLO; Project Type: Brownfield with UI
- Result: PASS with 2 PARTIAL items
  1. Update `.env.example` and README with `OPENROUTER_API_KEY` guidance.
  2. Confirm API documentation references `/api/ai` consistently (architecture & README).

## Dev Agent Record
- Assigned To: Dev Agent
- Priority: High
- File List:
  - `apps/web/.env.example`
  - `apps/web/README.md`
  - `apps/web/lib/validators.ts`
  - `apps/web/app/api/ai/route.ts`
  - `apps/web/app/(protected)/dashboard/page.tsx`
  - `apps/web/__tests__/api-ai-route.test.ts`
- Agent Model Used: Gemini
- Debug Log References: Tests passed after fixing import paths and installing openai package.
- Completion Notes List:
  - Implemented backend API route for AI chat streaming.
  - Integrated frontend with the new API endpoint.
  - Added new test file for the API route and ensured all tests pass.

## Change Log
- 2025-09-18: Completed implementation of backend AI chat stream, frontend wiring, and testing. Updated .env.example, README.md, lib/validators.ts, app/api/ai/route.ts, app/(protected)/dashboard/page.tsx, and added api-ai-route.test.ts.
- 2025-09-16: Initial draft created from PRD Epic 2, Story 2.3 with repo-aligned paths and testing plan.
- 2025-09-17: Updated acceptance criteria, tasks, and environment references for OpenRouter + optional `mode/model` per PRD/architecture v4.
